{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "206407cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import acquire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cb1da9",
   "metadata": {},
   "source": [
    "### Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it:\n",
    "\n",
    "- Lowercase everything\n",
    "- Normalize unicode characters\n",
    "- Replace anything that is not a letter, number, whitespace or a single quote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a69c669",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(string):\n",
    "    \n",
    "    string = string.lower()\n",
    "    string = unicodedata.normalize('NFKD', string).encode('ascii', 'ignore').decode('utf-8')\n",
    "    string = re.sub(r'[^a-z0-9\\'\\s]', '', string)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aae2529",
   "metadata": {},
   "source": [
    "### Define a function named tokenize. It should take in a string and tokenize all the words in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77532163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(string):\n",
    "    \n",
    "    tokenize = nltk.tokenize.ToktokTokenizer()\n",
    "    string = tokenize.tokenize(string, return_str=True)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa0bc33",
   "metadata": {},
   "source": [
    "### Define a function named stem. It should accept some text and return the text after applying stemming to all the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bfb0f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(string):\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    stems = [ps.stem(word) for word in string.split()]\n",
    "    string = ' '.join(stems)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b971ce27",
   "metadata": {},
   "source": [
    "### Define a function named lemmatize. It should accept some text and return the text after applying lemmatization to each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c3099f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(string):\n",
    "    \n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    lemmas = [wnl.lemmatize(word) for word in string.split()]\n",
    "    string = ' '.join(lemmas)\n",
    "\n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5524ed",
   "metadata": {},
   "source": [
    "### Define a function named remove_stopwords. It should accept some text and return the text after removing all the stopwords. This function should define two optional parameters, extra_words and exclude_words. These parameters should define any additional stop words to include, and any words that we don't want to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74603d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = [1,2,3,4,5]\n",
    "list2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ea82efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4, 5}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c90de6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "182d4324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4, 5}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(list1) - set(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72d877f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = set(list1).union(set(list2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7f99ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[numb for numb in numbers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b619aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(string, extra_words=[], exclude_words=[]):\n",
    "    stopwords_ls = stopwords.words('english')\n",
    "    \n",
    "    stopwords_ls = set(stopwords_ls) - set(exclude_words)\n",
    "    stopwords_ls = stopwords_ls.union(set(extra_words))\n",
    "    \n",
    "    words = string.split()\n",
    "    filtered_words = [word for word in words if word not in stopwords_ls]\n",
    "    string = ' '.join(filtered_words)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8f2580",
   "metadata": {},
   "source": [
    "### Use your data from the acquire to produce a dataframe of the news articles. Name the dataframe news_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "683a5200",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = acquire.get_news_articles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8784947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bandhan Bank onboards Sourav Ganguly as brand ...</td>\n",
       "      <td>Bandhan Bank has announced Sourav Ganguly as i...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Musk is under federal probe over his conduct i...</td>\n",
       "      <td>Twitter has claimed that the world's richest p...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Layoffs will be the absolute last thing at Zoh...</td>\n",
       "      <td>Software startup Zoho's CEO Sridhar Vembu said...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Infosys let go of employees working for two co...</td>\n",
       "      <td>Infosys CEO Salil Parekh has revealed that the...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Centre announces one-time aide for paddy straw...</td>\n",
       "      <td>Centre said it'll provide one-time financial s...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Was told I did 'Soch', 'Joker' for sympathy; c...</td>\n",
       "      <td>Singer Harrdy Sandhu said that he got messages...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>When father takes care of child, society blows...</td>\n",
       "      <td>Actress Neha Dhupia said she finds it \"problem...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Mind-blowing, a must-watch: Dhanush on Rishab ...</td>\n",
       "      <td>Actor Dhanush took to Twitter to praise Rishab...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Working with Salman Khan again in 'Tiger 3' is...</td>\n",
       "      <td>Speaking about working with actor Salman Khan ...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Always wanted to be like Big B, he's still goi...</td>\n",
       "      <td>Actor Ranveer Singh dedicated his Lokmat Mahar...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0   Bandhan Bank onboards Sourav Ganguly as brand ...   \n",
       "1   Musk is under federal probe over his conduct i...   \n",
       "2   Layoffs will be the absolute last thing at Zoh...   \n",
       "3   Infosys let go of employees working for two co...   \n",
       "4   Centre announces one-time aide for paddy straw...   \n",
       "..                                                ...   \n",
       "94  Was told I did 'Soch', 'Joker' for sympathy; c...   \n",
       "95  When father takes care of child, society blows...   \n",
       "96  Mind-blowing, a must-watch: Dhanush on Rishab ...   \n",
       "97  Working with Salman Khan again in 'Tiger 3' is...   \n",
       "98  Always wanted to be like Big B, he's still goi...   \n",
       "\n",
       "                                              content       category  \n",
       "0   Bandhan Bank has announced Sourav Ganguly as i...       business  \n",
       "1   Twitter has claimed that the world's richest p...       business  \n",
       "2   Software startup Zoho's CEO Sridhar Vembu said...       business  \n",
       "3   Infosys CEO Salil Parekh has revealed that the...       business  \n",
       "4   Centre said it'll provide one-time financial s...       business  \n",
       "..                                                ...            ...  \n",
       "94  Singer Harrdy Sandhu said that he got messages...  entertainment  \n",
       "95  Actress Neha Dhupia said she finds it \"problem...  entertainment  \n",
       "96  Actor Dhanush took to Twitter to praise Rishab...  entertainment  \n",
       "97  Speaking about working with actor Salman Khan ...  entertainment  \n",
       "98  Actor Ranveer Singh dedicated his Lokmat Mahar...  entertainment  \n",
       "\n",
       "[99 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df = pd.DataFrame(articles)\n",
    "news_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbd54f7",
   "metadata": {},
   "source": [
    "### Make another dataframe for the Codeup blog posts. Name the dataframe codeup_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f78e892e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "blogs = acquire.get_blog_articles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f44c604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date_published</th>\n",
       "      <th>category</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Diversity Equity and Inclusion Report</td>\n",
       "      <td>Oct 7, 2022</td>\n",
       "      <td>[Codeup News]</td>\n",
       "      <td>\\nCodeup is excited to launch our first Divers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Codeup Honored as SABJ Diversity and Inclusion...</td>\n",
       "      <td>Oct 7, 2022</td>\n",
       "      <td>[Codeup News]</td>\n",
       "      <td>\\nCodeup has been named the 2022 Diversity and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How Can I Finance My Career Transition?</td>\n",
       "      <td>Sep 29, 2022</td>\n",
       "      <td>[Cloud Administration, Data Science, Featured,...</td>\n",
       "      <td>\\nDeciding to transition into a tech career is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tips for Women Beginning a Career in Tech</td>\n",
       "      <td>Sep 23, 2022</td>\n",
       "      <td>[Tips for Prospective Students]</td>\n",
       "      <td>\\nCodeup strongly values diversity, and inclus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is Cloud Computing and AWS?</td>\n",
       "      <td>Sep 13, 2022</td>\n",
       "      <td>[Cloud Administration, Tips for Prospective St...</td>\n",
       "      <td>\\nWith many companies switching to cloud servi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title date_published  \\\n",
       "0              Diversity Equity and Inclusion Report    Oct 7, 2022   \n",
       "1  Codeup Honored as SABJ Diversity and Inclusion...    Oct 7, 2022   \n",
       "2            How Can I Finance My Career Transition?   Sep 29, 2022   \n",
       "3          Tips for Women Beginning a Career in Tech   Sep 23, 2022   \n",
       "4                   What is Cloud Computing and AWS?   Sep 13, 2022   \n",
       "\n",
       "                                            category  \\\n",
       "0                                      [Codeup News]   \n",
       "1                                      [Codeup News]   \n",
       "2  [Cloud Administration, Data Science, Featured,...   \n",
       "3                    [Tips for Prospective Students]   \n",
       "4  [Cloud Administration, Tips for Prospective St...   \n",
       "\n",
       "                                             content  \n",
       "0  \\nCodeup is excited to launch our first Divers...  \n",
       "1  \\nCodeup has been named the 2022 Diversity and...  \n",
       "2  \\nDeciding to transition into a tech career is...  \n",
       "3  \\nCodeup strongly values diversity, and inclus...  \n",
       "4  \\nWith many companies switching to cloud servi...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codeup_df = pd.DataFrame(blogs)\n",
    "codeup_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a200ad75",
   "metadata": {},
   "source": [
    "### For each dataframe, produce the following columns:\n",
    "\n",
    "- title to hold the title\n",
    "- original to hold the original article/post content\n",
    "- clean to hold the normalized and tokenized original with the stopwords removed.\n",
    "- stemmed to hold the stemmed version of the cleaned data.\n",
    "- lemmatized to hold the lemmatized version of the cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e16ec28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>original</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bandhan Bank onboards Sourav Ganguly as brand ...</td>\n",
       "      <td>Bandhan Bank has announced Sourav Ganguly as i...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Musk is under federal probe over his conduct i...</td>\n",
       "      <td>Twitter has claimed that the world's richest p...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Layoffs will be the absolute last thing at Zoh...</td>\n",
       "      <td>Software startup Zoho's CEO Sridhar Vembu said...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Infosys let go of employees working for two co...</td>\n",
       "      <td>Infosys CEO Salil Parekh has revealed that the...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Centre announces one-time aide for paddy straw...</td>\n",
       "      <td>Centre said it'll provide one-time financial s...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Bandhan Bank onboards Sourav Ganguly as brand ...   \n",
       "1  Musk is under federal probe over his conduct i...   \n",
       "2  Layoffs will be the absolute last thing at Zoh...   \n",
       "3  Infosys let go of employees working for two co...   \n",
       "4  Centre announces one-time aide for paddy straw...   \n",
       "\n",
       "                                            original  category  \n",
       "0  Bandhan Bank has announced Sourav Ganguly as i...  business  \n",
       "1  Twitter has claimed that the world's richest p...  business  \n",
       "2  Software startup Zoho's CEO Sridhar Vembu said...  business  \n",
       "3  Infosys CEO Salil Parekh has revealed that the...  business  \n",
       "4  Centre said it'll provide one-time financial s...  business  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df = news_df.rename(columns={'content':'original'})\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d12e1587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bandhan Bank onboards Sourav Ganguly as brand ...</td>\n",
       "      <td>Bandhan Bank has announced Sourav Ganguly as i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Musk is under federal probe over his conduct i...</td>\n",
       "      <td>Twitter has claimed that the world's richest p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Layoffs will be the absolute last thing at Zoh...</td>\n",
       "      <td>Software startup Zoho's CEO Sridhar Vembu said...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Infosys let go of employees working for two co...</td>\n",
       "      <td>Infosys CEO Salil Parekh has revealed that the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Centre announces one-time aide for paddy straw...</td>\n",
       "      <td>Centre said it'll provide one-time financial s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Bandhan Bank onboards Sourav Ganguly as brand ...   \n",
       "1  Musk is under federal probe over his conduct i...   \n",
       "2  Layoffs will be the absolute last thing at Zoh...   \n",
       "3  Infosys let go of employees working for two co...   \n",
       "4  Centre announces one-time aide for paddy straw...   \n",
       "\n",
       "                                            original  \n",
       "0  Bandhan Bank has announced Sourav Ganguly as i...  \n",
       "1  Twitter has claimed that the world's richest p...  \n",
       "2  Software startup Zoho's CEO Sridhar Vembu said...  \n",
       "3  Infosys CEO Salil Parekh has revealed that the...  \n",
       "4  Centre said it'll provide one-time financial s...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df = news_df[['title','original']]\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d429863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>original</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bandhan Bank onboards Sourav Ganguly as brand ...</td>\n",
       "      <td>Bandhan Bank has announced Sourav Ganguly as i...</td>\n",
       "      <td>bandhan bank has announced sourav ganguly as i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Musk is under federal probe over his conduct i...</td>\n",
       "      <td>Twitter has claimed that the world's richest p...</td>\n",
       "      <td>twitter has claimed that the world's richest p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Layoffs will be the absolute last thing at Zoh...</td>\n",
       "      <td>Software startup Zoho's CEO Sridhar Vembu said...</td>\n",
       "      <td>software startup zoho's ceo sridhar vembu said...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Infosys let go of employees working for two co...</td>\n",
       "      <td>Infosys CEO Salil Parekh has revealed that the...</td>\n",
       "      <td>infosys ceo salil parekh has revealed that the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Centre announces one-time aide for paddy straw...</td>\n",
       "      <td>Centre said it'll provide one-time financial s...</td>\n",
       "      <td>centre said it'll provide onetime financial su...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Bandhan Bank onboards Sourav Ganguly as brand ...   \n",
       "1  Musk is under federal probe over his conduct i...   \n",
       "2  Layoffs will be the absolute last thing at Zoh...   \n",
       "3  Infosys let go of employees working for two co...   \n",
       "4  Centre announces one-time aide for paddy straw...   \n",
       "\n",
       "                                            original  \\\n",
       "0  Bandhan Bank has announced Sourav Ganguly as i...   \n",
       "1  Twitter has claimed that the world's richest p...   \n",
       "2  Software startup Zoho's CEO Sridhar Vembu said...   \n",
       "3  Infosys CEO Salil Parekh has revealed that the...   \n",
       "4  Centre said it'll provide one-time financial s...   \n",
       "\n",
       "                                               clean  \n",
       "0  bandhan bank has announced sourav ganguly as i...  \n",
       "1  twitter has claimed that the world's richest p...  \n",
       "2  software startup zoho's ceo sridhar vembu said...  \n",
       "3  infosys ceo salil parekh has revealed that the...  \n",
       "4  centre said it'll provide onetime financial su...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df['clean'] = news_df.original.apply(basic_clean)\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d965278f",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - '/Users/vincentbanuelos/nltk_data'\n    - '/opt/homebrew/anaconda3/nltk_data'\n    - '/opt/homebrew/anaconda3/share/nltk_data'\n    - '/opt/homebrew/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/nltk/corpus/util.py:84\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m     root \u001b[39m=\u001b[39m nltk\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mfind(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msubdir\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mzip_name\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     85\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mLookupError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00msep\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mmsg\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00msep\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet.zip/wordnet/\u001b[0m\n\n  Searched in:\n    - '/Users/vincentbanuelos/nltk_data'\n    - '/opt/homebrew/anaconda3/nltk_data'\n    - '/opt/homebrew/anaconda3/share/nltk_data'\n    - '/opt/homebrew/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/vincentbanuelos/codeup-data-science/natural-language-processing-exercises/prepare_exercises.ipynb Cell 28\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vincentbanuelos/codeup-data-science/natural-language-processing-exercises/prepare_exercises.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m news_df[\u001b[39m'\u001b[39m\u001b[39mstemmed\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m news_df\u001b[39m.\u001b[39mclean\u001b[39m.\u001b[39mapply(stem)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/vincentbanuelos/codeup-data-science/natural-language-processing-exercises/prepare_exercises.ipynb#X36sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m news_df[\u001b[39m'\u001b[39m\u001b[39mlemmatized\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m news_df\u001b[39m.\u001b[39;49mclean\u001b[39m.\u001b[39;49mapply(lemmatize)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vincentbanuelos/codeup-data-science/natural-language-processing-exercises/prepare_exercises.ipynb#X36sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m news_df\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/core/series.py:4356\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4246\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4247\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4248\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4251\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4252\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m FrameOrSeriesUnion:\n\u001b[1;32m   4253\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4254\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4255\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4354\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4355\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4356\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py:1036\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39mstr\u001b[39m):\n\u001b[1;32m   1033\u001b[0m     \u001b[39m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m-> 1036\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py:1092\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1086\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m   1087\u001b[0m         \u001b[39m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m         \u001b[39m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[1;32m   1089\u001b[0m         \u001b[39m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[1;32m   1090\u001b[0m         \u001b[39m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m         \u001b[39m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[0;32m-> 1092\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   1093\u001b[0m             values,\n\u001b[1;32m   1094\u001b[0m             f,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1095\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   1096\u001b[0m         )\n\u001b[1;32m   1098\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1099\u001b[0m     \u001b[39m# GH 25959 use pd.array instead of tolist\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     \u001b[39m# so extension arrays can be used\u001b[39;00m\n\u001b[1;32m   1101\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(pd_array(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/_libs/lib.pyx:2859\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m/Users/vincentbanuelos/codeup-data-science/natural-language-processing-exercises/prepare_exercises.ipynb Cell 28\u001b[0m in \u001b[0;36mlemmatize\u001b[0;34m(string)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vincentbanuelos/codeup-data-science/natural-language-processing-exercises/prepare_exercises.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlemmatize\u001b[39m(string):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vincentbanuelos/codeup-data-science/natural-language-processing-exercises/prepare_exercises.ipynb#X36sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     wnl \u001b[39m=\u001b[39m nltk\u001b[39m.\u001b[39mstem\u001b[39m.\u001b[39mWordNetLemmatizer()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/vincentbanuelos/codeup-data-science/natural-language-processing-exercises/prepare_exercises.ipynb#X36sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     lemmas \u001b[39m=\u001b[39m [wnl\u001b[39m.\u001b[39mlemmatize(word) \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m string\u001b[39m.\u001b[39msplit()]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vincentbanuelos/codeup-data-science/natural-language-processing-exercises/prepare_exercises.ipynb#X36sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     string \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(lemmas)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vincentbanuelos/codeup-data-science/natural-language-processing-exercises/prepare_exercises.ipynb#X36sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m string\n",
      "\u001b[1;32m/Users/vincentbanuelos/codeup-data-science/natural-language-processing-exercises/prepare_exercises.ipynb Cell 28\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vincentbanuelos/codeup-data-science/natural-language-processing-exercises/prepare_exercises.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlemmatize\u001b[39m(string):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vincentbanuelos/codeup-data-science/natural-language-processing-exercises/prepare_exercises.ipynb#X36sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     wnl \u001b[39m=\u001b[39m nltk\u001b[39m.\u001b[39mstem\u001b[39m.\u001b[39mWordNetLemmatizer()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/vincentbanuelos/codeup-data-science/natural-language-processing-exercises/prepare_exercises.ipynb#X36sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     lemmas \u001b[39m=\u001b[39m [wnl\u001b[39m.\u001b[39;49mlemmatize(word) \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m string\u001b[39m.\u001b[39msplit()]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vincentbanuelos/codeup-data-science/natural-language-processing-exercises/prepare_exercises.ipynb#X36sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     string \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(lemmas)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vincentbanuelos/codeup-data-science/natural-language-processing-exercises/prepare_exercises.ipynb#X36sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m string\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/nltk/stem/wordnet.py:45\u001b[0m, in \u001b[0;36mWordNetLemmatizer.lemmatize\u001b[0;34m(self, word, pos)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlemmatize\u001b[39m(\u001b[39mself\u001b[39m, word: \u001b[39mstr\u001b[39m, pos: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mn\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m     34\u001b[0m     \u001b[39m\"\"\"Lemmatize `word` using WordNet's built-in morphy function.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[39m    Returns the input word unchanged if it cannot be found in WordNet.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39m    :return: The lemma of `word`, for the given `pos`.\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m     lemmas \u001b[39m=\u001b[39m wn\u001b[39m.\u001b[39;49m_morphy(word, pos)\n\u001b[1;32m     46\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mmin\u001b[39m(lemmas, key\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m) \u001b[39mif\u001b[39;00m lemmas \u001b[39melse\u001b[39;00m word\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/nltk/corpus/util.py:121\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__bases__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    119\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mLazyCorpusLoader object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m__bases__\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 121\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__load()\n\u001b[1;32m    122\u001b[0m \u001b[39m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[39m# __class__ to something new:\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, attr)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/nltk/corpus/util.py:86\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m             root \u001b[39m=\u001b[39m nltk\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mfind(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubdir\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mzip_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     85\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mLookupError\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m             \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m     88\u001b[0m \u001b[39m# Load the corpus.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m corpus \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__reader_cls(root, \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__kwargs)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/nltk/corpus/util.py:81\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m         root \u001b[39m=\u001b[39m nltk\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mfind(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msubdir\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__name\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     82\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mLookupError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     83\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m sep \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m*\u001b[39m \u001b[39m70\u001b[39m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00msep\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mmsg\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00msep\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - '/Users/vincentbanuelos/nltk_data'\n    - '/opt/homebrew/anaconda3/nltk_data'\n    - '/opt/homebrew/anaconda3/share/nltk_data'\n    - '/opt/homebrew/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "news_df['stemmed'] = news_df.clean.apply(stem)\n",
    "news_df['lemmatized'] = news_df.clean.apply(lemmatize)\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caed3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df, extra_words=[], exclude_words=[]):\n",
    "    df = df[['title','original']]\n",
    "    \n",
    "    df['clean'] = df.original\\\n",
    "                        .apply(basic_clean)\\\n",
    "                        .apply(tokenize)\\\n",
    "                        .apply(remove_stopwords, \n",
    "                                    extra_words=extra_words,\n",
    "                                    exclude_words=exclude_words)\n",
    "    df['stemmed'] = df.clean.apply(stem)\n",
    "    df['lemmatized'] = df.clean.apply(lemmatize)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2697a08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df_new = news_df.rename(columns={'content':'original'})\n",
    "codeup_df_new = codeup_df.rename(columns={'content':'original'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4256906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>original</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Infosys' attrition drops to 27.1%, net employe...</td>\n",
       "      <td>Infosys on Thursday reported a 1.3% QoQ drop i...</td>\n",
       "      <td>thursday reported 13 qoq drop voluntary attrit...</td>\n",
       "      <td>thursday report 13 qoq drop voluntari attrit r...</td>\n",
       "      <td>thursday reported 13 qoq drop voluntary attrit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We do not support dual employment: Infosys on ...</td>\n",
       "      <td>Infosys CEO Salil Parekh spoke on the moonligh...</td>\n",
       "      <td>ceo salil parekh spoke moonlighting debate ind...</td>\n",
       "      <td>ceo salil parekh spoke moonlight debat industr...</td>\n",
       "      <td>ceo salil parekh spoke moonlighting debate ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mukesh Ambani visits Kedarnath &amp; Badrinath shr...</td>\n",
       "      <td>Reliance Industries Chairman Mukesh Ambani on ...</td>\n",
       "      <td>reliance industries chairman mukesh ambani thu...</td>\n",
       "      <td>relianc industri chairman mukesh ambani thursd...</td>\n",
       "      <td>reliance industry chairman mukesh ambani thurs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Centre announces one-time aide for paddy straw...</td>\n",
       "      <td>Centre said it'll provide one-time financial s...</td>\n",
       "      <td>centre said ' provide onetime financial suppor...</td>\n",
       "      <td>centr said ' provid onetim financi support set...</td>\n",
       "      <td>centre said ' provide onetime financial suppor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IKEA lays off 10,000 employees after halting R...</td>\n",
       "      <td>Swedish ready-to-assemble furniture retailer I...</td>\n",
       "      <td>swedish readytoassemble furniture retailer ike...</td>\n",
       "      <td>swedish readytoassembl furnitur retail ikea sa...</td>\n",
       "      <td>swedish readytoassemble furniture retailer ike...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Wonderful experience to work with Rani Mukerji...</td>\n",
       "      <td>Recalling his Bollywood debut film 'Aiyyaa', M...</td>\n",
       "      <td>recalling bollywood debut film ' aiyyaa ' mala...</td>\n",
       "      <td>recal bollywood debut film ' aiyyaa ' malayala...</td>\n",
       "      <td>recalling bollywood debut film ' aiyyaa ' mala...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Always wanted to be like Big B, he's still goi...</td>\n",
       "      <td>Actor Ranveer Singh dedicated his Lokmat Mahar...</td>\n",
       "      <td>actor ranveer singh dedicated lokmat maharasht...</td>\n",
       "      <td>actor ranveer singh dedic lokmat maharashtrian...</td>\n",
       "      <td>actor ranveer singh dedicated lokmat maharasht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>'Ponniyin...' beats 'Vikram', becomes highest ...</td>\n",
       "      <td>Mani Ratnam's 'Ponniyin Selvan: I' has beaten ...</td>\n",
       "      <td>mani ratnam ' ' ponniyin selvan ' beaten kamal...</td>\n",
       "      <td>mani ratnam ' ' ponniyin selvan ' beaten kamal...</td>\n",
       "      <td>mani ratnam ' ' ponniyin selvan ' beaten kamal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SC questions need for pre-screening committee ...</td>\n",
       "      <td>The Supreme Court questioned the need for a pr...</td>\n",
       "      <td>supreme court questioned need prescreening com...</td>\n",
       "      <td>suprem court question need prescreen committe ...</td>\n",
       "      <td>supreme court questioned need prescreening com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>I'm speechless: Tanushree on Sajid Khan's part...</td>\n",
       "      <td>Actress Tanushree Dutta said she's \"speechless...</td>\n",
       "      <td>actress tanushree dutta said ' speechless film...</td>\n",
       "      <td>actress tanushre dutta said ' speechless filmm...</td>\n",
       "      <td>actress tanushree dutta said ' speechless film...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0   Infosys' attrition drops to 27.1%, net employe...   \n",
       "1   We do not support dual employment: Infosys on ...   \n",
       "2   Mukesh Ambani visits Kedarnath & Badrinath shr...   \n",
       "3   Centre announces one-time aide for paddy straw...   \n",
       "4   IKEA lays off 10,000 employees after halting R...   \n",
       "..                                                ...   \n",
       "95  Wonderful experience to work with Rani Mukerji...   \n",
       "96  Always wanted to be like Big B, he's still goi...   \n",
       "97  'Ponniyin...' beats 'Vikram', becomes highest ...   \n",
       "98  SC questions need for pre-screening committee ...   \n",
       "99  I'm speechless: Tanushree on Sajid Khan's part...   \n",
       "\n",
       "                                             original  \\\n",
       "0   Infosys on Thursday reported a 1.3% QoQ drop i...   \n",
       "1   Infosys CEO Salil Parekh spoke on the moonligh...   \n",
       "2   Reliance Industries Chairman Mukesh Ambani on ...   \n",
       "3   Centre said it'll provide one-time financial s...   \n",
       "4   Swedish ready-to-assemble furniture retailer I...   \n",
       "..                                                ...   \n",
       "95  Recalling his Bollywood debut film 'Aiyyaa', M...   \n",
       "96  Actor Ranveer Singh dedicated his Lokmat Mahar...   \n",
       "97  Mani Ratnam's 'Ponniyin Selvan: I' has beaten ...   \n",
       "98  The Supreme Court questioned the need for a pr...   \n",
       "99  Actress Tanushree Dutta said she's \"speechless...   \n",
       "\n",
       "                                                clean  \\\n",
       "0   thursday reported 13 qoq drop voluntary attrit...   \n",
       "1   ceo salil parekh spoke moonlighting debate ind...   \n",
       "2   reliance industries chairman mukesh ambani thu...   \n",
       "3   centre said ' provide onetime financial suppor...   \n",
       "4   swedish readytoassemble furniture retailer ike...   \n",
       "..                                                ...   \n",
       "95  recalling bollywood debut film ' aiyyaa ' mala...   \n",
       "96  actor ranveer singh dedicated lokmat maharasht...   \n",
       "97  mani ratnam ' ' ponniyin selvan ' beaten kamal...   \n",
       "98  supreme court questioned need prescreening com...   \n",
       "99  actress tanushree dutta said ' speechless film...   \n",
       "\n",
       "                                              stemmed  \\\n",
       "0   thursday report 13 qoq drop voluntari attrit r...   \n",
       "1   ceo salil parekh spoke moonlight debat industr...   \n",
       "2   relianc industri chairman mukesh ambani thursd...   \n",
       "3   centr said ' provid onetim financi support set...   \n",
       "4   swedish readytoassembl furnitur retail ikea sa...   \n",
       "..                                                ...   \n",
       "95  recal bollywood debut film ' aiyyaa ' malayala...   \n",
       "96  actor ranveer singh dedic lokmat maharashtrian...   \n",
       "97  mani ratnam ' ' ponniyin selvan ' beaten kamal...   \n",
       "98  suprem court question need prescreen committe ...   \n",
       "99  actress tanushre dutta said ' speechless filmm...   \n",
       "\n",
       "                                           lemmatized  \n",
       "0   thursday reported 13 qoq drop voluntary attrit...  \n",
       "1   ceo salil parekh spoke moonlighting debate ind...  \n",
       "2   reliance industry chairman mukesh ambani thurs...  \n",
       "3   centre said ' provide onetime financial suppor...  \n",
       "4   swedish readytoassemble furniture retailer ike...  \n",
       "..                                                ...  \n",
       "95  recalling bollywood debut film ' aiyyaa ' mala...  \n",
       "96  actor ranveer singh dedicated lokmat maharasht...  \n",
       "97  mani ratnam ' ' ponniyin selvan ' beaten kamal...  \n",
       "98  supreme court questioned need prescreening com...  \n",
       "99  actress tanushree dutta said ' speechless film...  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df(news_df_new, extra_words=['infosys'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32fa39e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>original</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the Math and Stats Principles You Nee...</td>\n",
       "      <td>Coming into our Data Science program, you will...</td>\n",
       "      <td>coming into our data science program you will ...</td>\n",
       "      <td>come into our data scienc program you will nee...</td>\n",
       "      <td>coming into our data science program you will ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Diversity Equity and Inclusion Report</td>\n",
       "      <td>Codeup is excited to launch our first Diversit...</td>\n",
       "      <td>codeup is excited to launch our first diversit...</td>\n",
       "      <td>codeup is excit to launch our first divers equ...</td>\n",
       "      <td>codeup is excited to launch our first diversit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tips for Women Beginning a Career in Tech</td>\n",
       "      <td>Codeup strongly values diversity, and inclusio...</td>\n",
       "      <td>codeup strongly values diversity and inclusion...</td>\n",
       "      <td>codeup strongli valu divers and inclus in hono...</td>\n",
       "      <td>codeup strongly value diversity and inclusion ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What Jobs Can You Get After a Coding Bootcamp?...</td>\n",
       "      <td>If you are interested in embarking on a career...</td>\n",
       "      <td>if you are interested in embarking on a career...</td>\n",
       "      <td>if you are interest in embark on a career in t...</td>\n",
       "      <td>if you are interested in embarking on a career...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Why You Should Become a Data Scientist</td>\n",
       "      <td>What do you look for in a career? Chances are,...</td>\n",
       "      <td>what do you look for in a career chances are y...</td>\n",
       "      <td>what do you look for in a career chanc are you...</td>\n",
       "      <td>what do you look for in a career chance are yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How Can I Finance My Career Transition?</td>\n",
       "      <td>Deciding to transition into a tech career is a...</td>\n",
       "      <td>deciding to transition into a tech career is a...</td>\n",
       "      <td>decid to transit into a tech career is a big s...</td>\n",
       "      <td>deciding to transition into a tech career is a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  What are the Math and Stats Principles You Nee...   \n",
       "1              Diversity Equity and Inclusion Report   \n",
       "2          Tips for Women Beginning a Career in Tech   \n",
       "3  What Jobs Can You Get After a Coding Bootcamp?...   \n",
       "4             Why You Should Become a Data Scientist   \n",
       "5            How Can I Finance My Career Transition?   \n",
       "\n",
       "                                            original  \\\n",
       "0  Coming into our Data Science program, you will...   \n",
       "1  Codeup is excited to launch our first Diversit...   \n",
       "2  Codeup strongly values diversity, and inclusio...   \n",
       "3  If you are interested in embarking on a career...   \n",
       "4  What do you look for in a career? Chances are,...   \n",
       "5  Deciding to transition into a tech career is a...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  coming into our data science program you will ...   \n",
       "1  codeup is excited to launch our first diversit...   \n",
       "2  codeup strongly values diversity and inclusion...   \n",
       "3  if you are interested in embarking on a career...   \n",
       "4  what do you look for in a career chances are y...   \n",
       "5  deciding to transition into a tech career is a...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  come into our data scienc program you will nee...   \n",
       "1  codeup is excit to launch our first divers equ...   \n",
       "2  codeup strongli valu divers and inclus in hono...   \n",
       "3  if you are interest in embark on a career in t...   \n",
       "4  what do you look for in a career chanc are you...   \n",
       "5  decid to transit into a tech career is a big s...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  coming into our data science program you will ...  \n",
       "1  codeup is excited to launch our first diversit...  \n",
       "2  codeup strongly value diversity and inclusion ...  \n",
       "3  if you are interested in embarking on a career...  \n",
       "4  what do you look for in a career chance are yo...  \n",
       "5  deciding to transition into a tech career is a...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df(codeup_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002cdd40",
   "metadata": {},
   "source": [
    "### Ask yourself:\n",
    "\n",
    "- If your corpus is 493KB, would you prefer to use stemmed or lemmatized text?\n",
    "- If your corpus is 25MB, would you prefer to use stemmed or lemmatized text?\n",
    "- If your corpus is 200TB of text and you're charged by the megabyte for your hosted computational resources, would you prefer to use stemmed or lemmatized text?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
